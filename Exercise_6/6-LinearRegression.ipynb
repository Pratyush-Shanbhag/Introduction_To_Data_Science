{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIS 9\n",
    "# Supervised Learning: Linear Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading\n",
    "<br>Think Stats: Correlation (Chapter 9)\n",
    "- 9.1 to 9.4\n",
    "- 9.7 to 9.8\n",
    "\n",
    "Python Data Handbook Chapter 5: Linear Regression\n",
    "- Simple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common type of supervised learning is a regression problem. \n",
    "- A regression, or regression predictive modeling, is the task of approximating a mapping function _f_  from a set of input features _X_  to some output labels _y_, such that when a new set of X features is presented, the function f can accurately predict the outcome y.\n",
    "- When the function f is a linear function, then it is a linear regression. \n",
    "- In a linear regression problem, the features X are the _independent variables_ and the labels _y_ are the _dependent variable_ because they're dependent on X.\n",
    "- The output y is quantitative data, a number that denotes a quantity such as a size or an amount within a range of values.\n",
    "- A regression with 1 variable X is a simple regression problem.\n",
    "A regression with 2 or more variables X1, X2... is a multiple regression problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with a small dataset of package delivery time data ([source](https://www.kaggle.com/gaurav9712/delivery-time)). The dataset has 2 columns of data: the sorting time and the delivery time. The sorting time is the time it takes to send the package out to delivery, and the delivery time is the time from when the package leaves the warehouse to the time it reaches the destination.\n",
    "<br>We want to see if we can predict the delivery time based on the sorting time. The sorting time is the X input, and the delivery time is the y output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Read data from `delivery.csv` into a DataFrame named __d__. Inpect the data by printing the number of rows and columns of the DataFrame, and print the first 5 lines of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (21, 2)\n",
      "   Delivery Time  Sorting Time\n",
      "0          21.00            10\n",
      "1          13.50             4\n",
      "2          19.75             6\n",
      "3          24.00             9\n",
      "4          29.00            10\n"
     ]
    }
   ],
   "source": [
    "d = pd.read_csv(\"delivery.csv\")\n",
    "print(\"Shape:\", d.shape)\n",
    "print(d.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Check whether there is any correlation between the sorting time and delivery time\n",
    "<br>Recall that a scatterplot can show correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# a. Start by shortening the column labels to Delivery and Sorting\n",
    "d.rename(columns=lambda x: x[:x.index(\" \")], inplace=True)\n",
    "# b. plot the data to check correlation\n",
    "plt.title(\"Sorting Time vs. Delivery Time\",fontsize=16)\n",
    "plt.xlabel(\"Sorting Time\",fontsize=12)\n",
    "plt.ylabel(\"Delivery Time\",fontsize=12)\n",
    "plt.scatter(d[\"Sorting\"], d[\"Delivery\"])\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. It looks like there is correlation, as the sorting time increases, the delivery time also increases. This means we can probably use linear regression as an estimator.\n",
    "<br>Create the linear regression estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.linear_model as lm\n",
    "\n",
    "regr = lm.LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. From the dataset, create the X DataFrame with the Sorting column, and create the y Series with the Delivery column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "X = d[[\"Sorting\"]]\n",
    "y = d[\"Delivery\"]\n",
    "print(type(X))\n",
    "prin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Train the estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[10  4  6  9 10  6  7  3 10  9  8  4  7  3  3  4  6  7  2  7  5].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/30/1rn1cd5d3y7g95b5l95wlklc0000gp/T/ipykernel_1138/681608568.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mregr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    516\u001b[0m         \u001b[0maccept_sparse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpositive\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'coo'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m         X, y = self._validate_data(X, y, accept_sparse=accept_sparse,\n\u001b[0m\u001b[1;32m    519\u001b[0m                                    y_numeric=True, multi_output=True)\n\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    431\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    869\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y cannot be None\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m     X = check_array(X, accept_sparse=accept_sparse,\n\u001b[0m\u001b[1;32m    872\u001b[0m                     \u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m                     \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    692\u001b[0m             \u001b[0;31m# If input is 1D raise error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    695\u001b[0m                     \u001b[0;34m\"Expected 2D array, got 1D array instead:\\narray={}.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[10  4  6  9 10  6  7  3 10  9  8  4  7  3  3  4  6  7  2  7  5].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "regr = regr.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Print the _coefficients_ (the m value) and the _intercepts_ (the b value) of y = mx + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Coefficients:', regr.coef_)\n",
    "print('Intercepts:', regr.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. With the coefficient and intercept values, plot the linear regression line that fits the scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X, regr.coef_ * X + regr.intercept_, color='green')\n",
    "plt.scatter(d.Sorting,d.Delivery)    \n",
    "plt.title(\"Sorting time vs Delivery time\")\n",
    "plt.xlabel(\"Sorting time\")\n",
    "plt.ylabel(\"Delivery time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Theoretically we can now predict the delivery time, given the sorting time of a package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually input an X value, then calculate y = mx + b\n",
    "s_time = 12\n",
    "d_time = regr.coef_ * s_time + regr.intercept_\n",
    "print(d_time)\n",
    "# or when there are many X values:\n",
    "regr.predict([[12.0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. But is the prediction any good? Does the model work well for this type of data?\n",
    "<br>It's common practice to take the set of data and break it up into 2 parts: training data and test data. This way we have multiple test data to test the estimator. We use the training data to train the estimator, and then use the test data to check the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Use the test data as input, then observe the predicted output with the actual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regr.predict(X_test)\n",
    "# use a DataFrame to visually compare the 2 actual data and the predicted data\n",
    "df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. The actual and predicted data are not expected to be identical, but the closer they are the better our estimator is working. There are some common measurements of how well the estimator works:\n",
    "- The root mean squared error, abbreviated as RMSE\n",
    "- The R-squared value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "RMSE = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:',round(RMSE,2))\n",
    "print('R^2 value:', round(regr.score(X,y),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RMSE is the square root of the mean of squared errors, where error is the difference between actual and predicted data points. It is the standard deviation of the difference between predicted data and actual data. A lower RSME is a better fit, but keep in mind that this is not an absolute value. It is a value which is compared with the range of y values to determine whether it's a small or large value. \n",
    "\n",
    "Another common measurement of how well the estimator works for a type of data is the $R^{2}$ value or the _coefficient of determination_. It is a percentage of the y labels that are explained by the X features. An $R^{2}$ value of 1.0 (100%) is a perfect fit, and a value of 0.0 (0%) means there is no fit. An $R^{2}$ value of 0.85 means that the X features can predict 85% of the y output.\n",
    "\n",
    "Depending on the data that we work with, sometimes a low R value is acceptable if there are other significant trends. Likewise, a high R value doesn't necessarily mean the estimator is good. If the differences between actual data and the linear regression line mostly cancel each other out (such as +22.5 and -22.5) then the R value can be high and yet the difference (22.5) could be large compared to the mean of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__More examples of simple linear regression__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We look at the data in `marketing.csv` ([source](https://www.kaggle.com/fayejavad/marketing-linear-multiple-regression)). The data are 3 marketing budgets and the corresponding sales figures, in thousands of dollars."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. Read data from `marketing.csv` into a DataFrame named __d__, show the size of the data and the first 5 lines of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to see if marketing the product on each of the 3 platforms have a direct effect on the sales figures.\n",
    "<br>First we look at youtube."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. Create a plot to see the correlation between the youtube and sales data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15. Create the X and y variables, split the data into training and test sets, train the estimator, and print the RMSE and R squared values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# youtube\n",
    "X = d.youtube.to_frame()\n",
    "y = d.sales\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "regr = lm.LinearRegression()\n",
    "regr = regr.fit(X_train, y_train)\n",
    "y_pred = regr.predict(X_test)\n",
    "RMSE = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:',round(RMSE,2))\n",
    "print('R^2 value:', round(regr.score(X,y),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16. Plot the linear regression line to show the fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17. Do the same 3 steps for facebook data: show the correlation, show how well the estimator works, show the fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show correlation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show how well the estimator works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18. Do the same 3 steps for newspaper data: show the correlation, show how well the estimator works, show the fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show how well the estimator works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a multiple linear regression or multivariate linear regression, there are multiple X features that could affect the y output. The steps for multiple linear regression is similar to the steps for simple linear regression. The difference is that we can find out which X features affects the output the most, and the relationship between the X features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "19. We look at a small dataset from `homeprices.csv` ([source](https://www.kaggle.com/pankeshpatel/homepricesmultiplevariables)). The data consists of sales prices of homes with certain size (square ft), bedrooms, and age. (The houses in the dataset are definitely not from the Bay Area!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "homeprice = pd.read_csv('homeprices.csv') \n",
    "print(homeprice.shape)\n",
    "homeprice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20. Set X to the area and age, and y to the price. Print the size of X and y to check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = homeprice[['area','age']]\n",
    "y = homeprice.price\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "21. Plot 2 figures side by side to show the correlation of area and price, and of age and price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "22. Since there is correlation, split the X and y into training and testing sets. Print the size of the sets to check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "23. Train the estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = lm.LinearRegression()\n",
    "regr = regr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "24. The estimator has to find the most optimal coefficients for all the X attributes. We see what coefficients the estimator has chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff = pd.DataFrame(regr.coef_, X.columns, columns=['Coefficient'])\n",
    "coeff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the age has more influence on the output than the area. We also see that as the price (the output) goes up, the area also goes up and the age goes down. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "25. Test the estimator and show the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regr.predict(X_test)\n",
    "df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "26. Show the RMSE and R-squared values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:',round(RMSE,2))\n",
    "print('R^2 value:', round(regr.score(X,y),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above example is a simple example of multivariable linear regression, but it is not a good case study because the sample size of 6 is much too small. \n",
    "\n",
    "There are online resources for looking up or calculating sample sizes for statistical purpose, such as medical applications or social science applications. But there are also some general rule of thumbs for sample sizes. Generally a sample size of 100 is the minimum for small population (or all the population if it's less than 100), or a percent of the population for a larger population. \n",
    "\n",
    "Here's an optional, easy-to-read [article](https://tools4dev.org/resources/how-to-choose-a-sample-size/) on determining sample size for basic applications, with links to more in-depth articles for those who are statistically trained.\n",
    "\n",
    "For machine learning, a training daset is typically larger than one used for statistical sampling. The size of the training data depends on how many X features there are, the type of machine learning model, the subject area, etc. Here's an [article](https://machinelearningmastery.com/much-training-data-required-machine-learning/) that goes over some considerations when determining training datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
