{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CIS 9 - Lab 4: NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name: Pratyush Shanbhag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 2 NLP problems in this lab. They are in Part 1 and Part 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import files\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "rom nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1\n",
    "\n",
    "Use NLTK to build a model that analyzes movie reviews to determine if the reviews say that the movie is good or bad.<br>\n",
    "The input file has reviews from the website Rotten Tomatoes and is named _rottentomatoes.csv_ ([source](https://www.kaggle.com/code/amilsilahic/rotten-tomatoes-sentiment/data?select=data_rt.csv)).<br>\n",
    "In the file the label 1 means it's a good movie, and the label 0 means it's a bad movie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. __Read data from the file _rottentomatoes.csv_ into a DataFrame__.<br>\n",
    "Then __print the number of rows and columns of the DataFrame__,<br>\n",
    "and __print the first 5 rows__ to observe the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.  __Check to see if there are NaN__ and __drop the rows with NaN__ if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. __Check if the labels are balanced data__.<br>\n",
    "Then __create a Raw NBConvert cell to indicate whether the data is balanced__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. __Print the index of good movies and the bad movies__.<br>\n",
    "Then __create a Raw NBConvert cell to explain where the good movies and bad movies are in the DataFrame__.<br>\n",
    "Example of explanation: good movies are in row index 0 - 3000 and 5000-8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. __Create the X and y datasets__<br>\n",
    "Then __print the number of rows and columns of X and y__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. __Process the X dataset to remove stop words__<br>\n",
    "then __print the first 5 rows of the resulting processed X dataset__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7a. Now that the stop words are removed, let's see what the top 10 words for the good and bad movies are.<br>\n",
    "__Find and plot the top 10 most used words in reviews for good movies__<br>\n",
    "Hint: the result of step 4 can help you select the reviews for good movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7b. __Find and plot the top 10 most used words in review for bad movies__<br>\n",
    "Hint: the result of step 4 can help you select the reviews for bad movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7c. __Create a Raw NBConvert cell__ to explain whether the top 10 words in a review are a good indication of good vs bad movies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. __Convert the processed X dataset to vectors of numbers__<br>\n",
    "Then __print the shape of the X vectors__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. __Divide the X vectors and y datasets into training and testing set__<br>\n",
    "Then __print the shape of each set__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. __Train the MultinomialNB model with the training data__<br>\n",
    "Then __test it with the testing data__ and __print both the accuracy score and the confusion matrix__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Now we test the model with a completely new dataset<br>\n",
    "__Read the file _movies.csv_ in to a DataFrame__. _movies.csv_ has movie reviews from the website IMDb ([source](https://www.kaggle.com/datasets/yasserh/imdb-movie-ratings-sentiment-analysis))<br>\n",
    "Then __print the number of rows and columns of the DataFrame__ and __print the first 5 rows__ to inspect the data.<br>\n",
    "In the dataset, a label of 0 means bad movie, and a label of 1 means good movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Skipping the steps to check for balanced data and to check for NaN (they've been checked for you):<br>\n",
    "__Create the X and y datasets__ and __print the number of rows and columns__ of each set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. __Process the X dataset__ <u>in the same way</u> that you processed the X data from Rotten Tomatoes above.<br>\n",
    "Then __print the first 5 rows of the processed X dataset__<br>\n",
    "Take advantage of code re-use, now is not the time to blindly copy-and-paste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. __Convert the processed X strings into vectors__ <u>in the same way</u> as you did for the Rotten Tomatoes reviews.<br>\n",
    "Then __print the shape of the X vectors__<br>\n",
    "Take advantage of code re-use, now is definitely not the time to blindly copy-and-paste.<br>\n",
    "\n",
    "(If you copy-and-paste from above, it's guaranteed not to work. You need to understand what goes on above to know what to re-use.<br> Yes, it's the last lab and I'm showing my evil self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15. __Test the NLP model that you've trained above with the new X vectors__<br>\n",
    "Then __print the accuracy and confusion matrix__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2\n",
    "\n",
    "Use NLTK to create a model that can identify the (human) language of a given text string.<br>\n",
    "The model will \"learn\" the languages from the file _languagedetection.csv_ ([source](https://www.kaggle.com/code/emirhanai/language-detection-artificial-intelligence-97-f1/data?select=language_detection.csv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. __Read data from _languagedetection.csv_ into a DataFrame.__<br>\n",
    "Then __print the number of rows and columns of the DataFrame__<br>\n",
    "and __print the first 10 rows of data__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Given that there is no NaN in the file, __print the number of unique languages that are in the dataset__.<br>\n",
    "Then __print each language and the corresponding number of strings (rows) with that language__.<br>\n",
    "The second output should be a list of 1 instance of each language, and the corresponding count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. __Change each languages to a unique number__.<br>\n",
    "Then __print the first 5 rows of the DataFrame__.<br>\n",
    "You should not have to type all the languages individually to do the conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. __Create the X and y datasets from the DataFrame__.<br>\n",
    "Then __print the number of rows and columns of X and y__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. __Prepare the X dataset to use with the MultinomialNB model__<br>\n",
    "You'll need to decide what preparation is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. __Create the training and testing sets__ from the prepared X dataset and y dataset.<br>\n",
    "Then __print the shape of each training and testing set__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. __Train and test the MultinomialNB model__, then __print the accuracy of the model__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EC\n",
    "\n",
    "Since this is the last lab, the following part is extra credit (2pts) and is optional.<br>\n",
    "For the EC, you'll let the user enter text strings in different languages, and the model will try to identify the language.<br>\n",
    "If the user enters a language that the model has not been trained with, it will guess within the trained languages and will be wrong."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. __Create a look up table that's the reverse look up of how you converted the language name to a number__.<br>\n",
    "For example, if English was converted to 20, then this look up table will return English when given the number 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. __Write a function__ that will:\n",
    "- accept a text string\n",
    "- convert the string to a list of 1 string:  `listOfString = [aString]` if `aString` is a Python string\n",
    "- prepare the list of 1 string and pass it to the model \n",
    "- convert the output from the model (a number) back to the language (for example, 20 => English)\n",
    "- return the language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. __Fill in your function name below__ (don't leave is as your_function_name, you're more professional than that)<br>\n",
    "and __uncomment to test your model__.<br>\n",
    "The sample output is included below but will be gone when you run the cell with your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your text: Veni, vidi, vici\n",
      "Language: Latin\n",
      "Enter your text: c'est la vie\n",
      "Language: French\n",
      "Enter your text: Mulțumesc foarte mult\n",
      "Language: Romanian\n",
      "Enter your text: ¿Qué te gusta hacer?\n",
      "Language: Spanish\n",
      "Enter your text: Como vai?\n",
      "Language: Portugese\n",
      "Enter your text: one two three four\n",
      "Language: English\n",
      "Enter your text: \n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "while True :\n",
    "    text = input(\"Enter your text: \")\n",
    "    if len(text) == 0 :\n",
    "        break\n",
    "    print(\"Language:\", your_function_name(text))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
